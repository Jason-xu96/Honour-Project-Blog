<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" href="blog-overview.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
</head>
<!--  This is a w3schools template: https://www.w3schools.com/howto/howto_css_blog_layout.asp -->
<body>
    <div class="header">
        <h2>Zhikan's Undergraduate Honours Project Blog</h2>
    </div>    
    <div class="row">
        <div>
            <div class="card">
                <h2>Bi-weekly Update</h2>
                <h5>Sep 15, 2019</h5>
                <p>
                    1. Went through AIBO Programming Tutorial at https://www.cc.gatech.edu/~tucker/courses/amrs/aibo/AIBOProgrammingTutorial.pdf
                    <br>
                    Learned about OPENR objects and their communication mechanism
                    <br>
                    2. Read the general overview of the Aibo software development environment on Aibo wikipedia page at https://en.wikipedia.org/wiki/AIBO#Software
                    <br>
                    Knew that the two main ways of programming Aibo are: OPEN-R SDK and R-CODE and R-CODE plus
                </p>
            </div>
            <hr>
            <div class="card">
                <h2>Project Proposal</h2>
                <h5>September 14, 2019</h5>
                <p>
                    <h4>
                        <center>
                            COMP 4520 – Undergraduate Honours Project Proposal
                            <br>
                            Aibo’s behaviours to convey its states and intentions
                            <br>
                            Zhikan Xu
                            <br>
                            Supervisor: James E. Young
                        </center>
                    </h4>
                    <h4>I. Abstract:</h4>
                        Robots come in all shapes and sizes. Some scientists draw their inspiration from animals. Unlike
                        their humanoid counterparts, animal-inspired robots are not expected to speak human languages,
                        so how they communicate with humans becomes a challenge. This project looks into a robot dog
                        Aibo. By examining how humans perceive and react to its certain movements, we could find out
                        the most effective behaviours to convey its states and intentions.
                    <h4>II. Introduction to the topic:</h4>
                        There are still lots of unknowns when it comes to the most effective, universal behaviours for an
                        animal robot to communicate with humans. Many motions could be interpreted differently
                        depending on a user’s cultural background. Various research papers from the HCI lab at
                        University of Manitoba have looked into this issue.
                    <h4>III. Your background preparation to do this project:</h4>
                        I completed HCI I, II, and Graphic I, which give me a solid understanding of how humans
                        perceive and interact with computing technology.
                        My previous summer research term immersed me in a research environment and equipped me
                        with better problem-solving skills.
                    <h4>IV. Related work:</h4>
                        A Dog Tail Interface for Communicating Affective States of Utility Robots by Ashish Singh.
                        Adapting the Laban Effort System to Design Affect-Communicating Locomotion Path for a
                        Flying Robot by Megha Sharma.
                    <h4>V. Problem Statement:</h4>
                        Evaluate the feasibility of running formal experiments on what
                        behaviours are the most effective in communicating an Aibo’s intentions and states to its user.
                    <h4>VI. Methodology:</h4>
                        Timeboxing helps break down the schedule into timeboxes with each timebox having its own deliverables.
                        <table>
                            <tr>
                                <th>Deadline</th>
                                <th>Deliverables</th>
                            </tr>
                            <tr>
                                <td>Early Nov</td>
                                <td>Custom behaviours programmed on Aibo</td>
                            </tr>
                            <tr>
                                <td>Late Nov</td>
                                <td>Design of pilot experiments</td>
                            </tr>
                            <tr>
                                <td>Mid Dec</td>
                                <td>Data collected from pilot experiments</td>
                            </tr>
                        </table>
                    <h4>VII. Infrastructure and facilities and expert personnel required:
                        An Aibo robot dog with an open API that allows a programmer to access Aibo’s hardware</h4>
                        features.
                    <h4>VIII. Outcome and Deliverables:</h4>
                        I expect to have a set of custom behaviours programmed on an Aibo and conduct pilot
                        experiments on finding the most effective Aibo behaviours to convey its intentions and states.
                    <h4>References:</h4>
                        Sharma, M. (2013). Affective Flying-Robot Motions via the Laban Effort System. Retrieved from HCI Lab
                        University of Manitoba: http://hci.cs.umanitoba.ca/projects-and-research/details/adapting-thelaban-effort-system-to-design-affect-communicating-locomotion
                        <br>
                        Singh, A. (2013). A Dog Tail for Robots (2013). Retrieved from HCI Lab University of Manitoba:
                        http://hci.cs.umanitoba.ca/projects-and-research/details/exploring-animal-inspired-humanrobot-interaction
                </p>
            </div>
        </div>
    </div>
</body>