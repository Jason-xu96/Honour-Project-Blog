<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" href="blog-overview.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
</head>
<!--  This is a w3schools template: https://www.w3schools.com/howto/howto_css_blog_layout.asp -->
<body>
    <div class="header">
        <h2>Zhikan's Undergraduate Honours Project Blog</h2>
    </div>    
    <div class="row">
        <div>
            <div class="card">
                <h2>Weekly Update</h2>
                <h5>Sep 25, 2019</h5>
                <p>
                    1. Went through AIBO Programming Tutorial at http://aibostuff.iofreak.com/wiki.php?n=Aibo.Development
                    <br>
                    Familiarized myself with R-CODE syntax and some sample programs.
                    <br>
                    2. Found out that Sony postponed its open API release to Fall 2019 according to https://prtimes.jp/main/html/rd/p/000000044.000024857.html
                    <br>
                    Dr. Jim Young is reaching out to his connections to find out when exactly the open API will be released.
                    <br>
                    3. Was recommended by Dr. JIm Young to look into a programming framework called "Tekkotsu".
                    <br>
                    Started to look into its manual at http://www.tekkotsu.org/about.html
                    <br>
                    4. Found that the pink memory stick is on sale at https://www.ebay.ca/itm/Rare-SONY-16MB-Memory-Stick-AIBO-ERA-MS016-NEW-SEALED/383107582403?hash=item5932fdc9c3:g:-nUAAOSwjW5dV4-x
                    <br>
                    The pink memory stick is required for programming the old Aibo
                </p>
            </div>
            <div class="card">
                <h2>Weekly Update</h2>
                <h5>Sep 17, 2019</h5>
                <p>
                    1. Found out that Sony was supposed to release its open API for the latest Aibo ERS-1000 in August according to https://spectrum.ieee.org/automaton/robotics/home-robots/sony-upgrading-aibo-with-new-home-security-features-api-access
                    <br>
                    But there isn't any API released by Sony as of Sep 17, 2019, so Dr. Young suggested to program the old Aibo ERS-7 first.
                    <br>
                    I also sent an email to Sony regarding when the API will come out, and haven't got a response yet.
                    <br>
                    2. Went through AIBO Programming Tutorial at https://www.cc.gatech.edu/~tucker/courses/amrs/aibo/AIBOProgrammingTutorial.pdf
                    <br>
                    Learned about OPENR objects and their communication mechanism
                    <br>
                    3. Read the general overview of the Aibo software development environment on Aibo wikipedia page at https://en.wikipedia.org/wiki/AIBO#Software
                    <br>
                    Found out that the three main ways of programming Aibo are: OPEN-R SDK, R-CODE, and AIBO remote framework.
                    <br>
                    4. Compared different software development environments from http://aibostuff.iofreak.com/wiki.php?n=Aibo.Development
                    <br>
                    Started look into R-CODE syntax since it is high-level and easy to grasp.
                </p>
            </div>
            <hr>
            <div class="card">
                <h2>Project Proposal</h2>
                <h5>September 14, 2019</h5>
                <p>
                    <h4>
                        <center>
                            COMP 4520 – Undergraduate Honours Project Proposal
                            <br>
                            Aibo’s behaviours to convey its states and intentions
                            <br>
                            Zhikan Xu
                            <br>
                            Supervisor: James E. Young
                        </center>
                    </h4>
                    <h4>I. Abstract:</h4>
                        Robots come in all shapes and sizes. Some scientists draw their inspiration from animals. Unlike
                        their humanoid counterparts, animal-inspired robots are not expected to speak human languages,
                        so how they communicate with humans becomes a challenge. This project looks into a robot dog
                        Aibo. By examining how humans perceive and react to its certain movements, we could find out
                        the most effective behaviours to convey its states and intentions.
                    <h4>II. Introduction to the topic:</h4>
                        There are still lots of unknowns when it comes to the most effective, universal behaviours for an
                        animal robot to communicate with humans. Many motions could be interpreted differently
                        depending on a user’s cultural background. Various research papers from the HCI lab at
                        University of Manitoba have looked into this issue.
                    <h4>III. Your background preparation to do this project:</h4>
                        I completed HCI I, II, and Graphic I, which give me a solid understanding of how humans
                        perceive and interact with computing technology.
                        My previous summer research term immersed me in a research environment and equipped me
                        with better problem-solving skills.
                    <h4>IV. Related work:</h4>
                        A Dog Tail Interface for Communicating Affective States of Utility Robots by Ashish Singh.
                        Adapting the Laban Effort System to Design Affect-Communicating Locomotion Path for a
                        Flying Robot by Megha Sharma.
                    <h4>V. Problem Statement:</h4>
                        Evaluate the feasibility of running formal experiments on what
                        behaviours are the most effective in communicating an Aibo’s intentions and states to its user.
                    <h4>VI. Methodology:</h4>
                        Timeboxing helps break down the schedule into timeboxes with each timebox having its own deliverables.
                        <table>
                            <tr>
                                <th>Deadline</th>
                                <th>Deliverables</th>
                            </tr>
                            <tr>
                                <td>Early Nov</td>
                                <td>Custom behaviours programmed on Aibo</td>
                            </tr>
                            <tr>
                                <td>Late Nov</td>
                                <td>Design of pilot experiments</td>
                            </tr>
                            <tr>
                                <td>Mid Dec</td>
                                <td>Data collected from pilot experiments</td>
                            </tr>
                        </table>
                    <h4>VII. Infrastructure and facilities and expert personnel required:
                        An Aibo robot dog with an open API that allows a programmer to access Aibo’s hardware</h4>
                        features.
                    <h4>VIII. Outcome and Deliverables:</h4>
                        I expect to have a set of custom behaviours programmed on an Aibo and conduct pilot
                        experiments on finding the most effective Aibo behaviours to convey its intentions and states.
                    <h4>References:</h4>
                        Sharma, M. (2013). Affective Flying-Robot Motions via the Laban Effort System. Retrieved from HCI Lab
                        University of Manitoba: http://hci.cs.umanitoba.ca/projects-and-research/details/adapting-thelaban-effort-system-to-design-affect-communicating-locomotion
                        <br>
                        Singh, A. (2013). A Dog Tail for Robots (2013). Retrieved from HCI Lab University of Manitoba:
                        http://hci.cs.umanitoba.ca/projects-and-research/details/exploring-animal-inspired-humanrobot-interaction
                </p>
            </div>
        </div>
    </div>
</body>